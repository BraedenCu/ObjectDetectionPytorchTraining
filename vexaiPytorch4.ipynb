{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vexaiPytorch4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwaw/K5FHCxbhJDJ+zdoXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BraedenCu/ObjectDetectionWithPytorchTutorial/blob/master/vexaiPytorch4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qt8uw-rTC-N",
        "colab_type": "text"
      },
      "source": [
        "Import necessary packages (should be automatically installed in colab)\n",
        "If you get an import error, install each of them using python3 -m pip install ____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8gdyAcwTQzI",
        "colab_type": "text"
      },
      "source": [
        "Next we clone my fork of the pytorch vision repository, which contains scripts we will use later. Then clone some useful scripts for data manipluation from my repository. Finally, create directories for annotations and images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKcuIruY6HrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVERYTIME KERNEL DIES, YOU NEED TO REUPLOAD XMLS AND IMAGES\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import pycocotools\n",
        "import os\n",
        "\n",
        "%cd /root/\n",
        "#need to clone my fork, elsewise it will throw import error when using one of the libraries\n",
        "#remove and previous installation, clone the most recent\n",
        "!rm -r vision\n",
        "!git clone https://github.com/BraedenCu/vision.git\n",
        "!cd vision\n",
        "!git checkout v0.6.0\n",
        "\n",
        "%cd ~\n",
        "#remove any previous clone of the repo and install the latest release \n",
        "!rm -r scriptsForObjectDetectionDataPreparation/\n",
        "!git clone https://github.com/BraedenCu/scriptsForObjectDetectionDataPreparation.git\n",
        "!mkdir annotations\n",
        "!mkdir images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGlgp2JTmD7",
        "colab_type": "text"
      },
      "source": [
        "Here we are first removing any prevois copys of the following scripts and updating them. These scripts will be used later for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2471OV_3CH_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in order to gain access to functions defined in engine.py/utils.py/etc. we need to copy\n",
        "#the python scripts to root\n",
        "%cd /root/\n",
        "#remove old versions of the python scripts and replace with updated ones\n",
        "!rm -r engine.py\n",
        "!rm -r coco_eval.py\n",
        "!rm -r coco_utils.py\n",
        "!rm -r utils.py\n",
        "%cd vision\n",
        "%cd references\n",
        "%cd detection\n",
        "#copy files to root\n",
        "!cp engine.py -b /root/\n",
        "!cp utils.py -b /root/\n",
        "!cp coco_utils.py -b /root/\n",
        "!cp coco_eval.py -b /root/\n",
        "#change directory back to root\n",
        "%cd /root/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF9-Y2fkXtfs",
        "colab_type": "text"
      },
      "source": [
        "Convert to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2PugJl-r5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ~/scriptsForObjectDetectionDataPreparation/\n",
        "#convert xml_to_csv, if it failes to create do to empty csv, be sure to check that you have uploaded your images and annottions\n",
        "#remove and reupdate\n",
        "!rm -r vex_labels.csv\n",
        "!python xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgY60oZu-wDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "#function to return data when given filename\n",
        "def parse_one_annot(path_to_csv_file, filename):\n",
        "   data = pd.read_csv(path_to_csv_file)\n",
        "   boxes_array = data[data[\"filename\"] == filename][[\"xmin\", \"ymin\",        \n",
        "   \"xmax\", \"ymax\"]].values\n",
        "   #print(boxes_array)\n",
        "   return boxes_array\n",
        "\n",
        "   \n",
        "class vex(object):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to\n",
        "        # ensure that they are aligned\n",
        "        self.imgs = \"/root/images\" #sorted(os.listdir(os.path.join(root, \"images\")))\n",
        "        self.csv_path = \"/root/scriptsForObjectDetectionDataPreparation/vex_labels.csv\"\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        #simply just repeat 1 rather than search for 0.jpeg, which does not exist\n",
        "        if idx == 0:\n",
        "          idx = 1\n",
        "        \n",
        "        img_path = \"/root/images/{}{}\".format(idx, \".jpeg\")\n",
        "        #print(img_path)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        \n",
        "        # convert the PIL Image into a numpy array\n",
        "        #box_list = parse_one_annot(self.csv_path, self.imgs[idx])\n",
        "        box_list = parse_one_annot(self.csv_path, img_path)\n",
        "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
        "        num_objs = len(box_list)\n",
        "        # 5 classes, so five boxes to be either zero or one\n",
        "        num_objs = 5\n",
        "        labels = torch.ones((num_objs), dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "    \n",
        "        # convert everything into a torch.Tensor\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # there is only one class\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        #target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        #if self.transforms is not None:\n",
        "        img = self.transforms(img)\n",
        "            #target = self.transforms(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        #return len(self.imgs)\n",
        "        return 204"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgIaP4LwXWgZ",
        "colab_type": "text"
      },
      "source": [
        "Below just checks to make sure your image path is correct.\n",
        "I spent alot of time smashing my head on my keyboard attempting to solve meaningless errors when it was simply due to an incorrect image path. Don't be me, check to make sure the path is correct. After you run this code you must rerun the above excerpt. (then comment it back out)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXUJWHIdhFpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#makes sure image path is correct\n",
        "#img_path = \"/root/images/{}{}\".format(idx, \".jpeg\")\n",
        "#print(img_path)\n",
        "#img = Image.open(img_path).convert(\"RGB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFHYgauaXA9F",
        "colab_type": "text"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYjvCltYfhDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_instance_segmentation(num_classes):\n",
        "   # load an object detection model pre-trained on COCO\n",
        "   model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  # get the number of input features for the classifier\n",
        "   in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "   # replace the pre-trained head with a new on\n",
        "   model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "   \n",
        "   return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3h2YLqFW72v",
        "colab_type": "text"
      },
      "source": [
        "Need to convert all images to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjL3M4nlCBz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToTensor())\n",
        "    return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQwYdrxWvq4",
        "colab_type": "text"
      },
      "source": [
        "Below is simply a test to make sure the data pipepile is functional, you do not need to run this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddplJWutCW63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "dataset = vex('/root/', get_transform(train=True))\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        " dataset, batch_size=2, shuffle=True, num_workers=4,\n",
        " collate_fn=utils.collate_fn)\n",
        "\n",
        "# For Training\n",
        "images,targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets) \n",
        "\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)           # Returns predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcpWkCfwWdfL",
        "colab_type": "text"
      },
      "source": [
        "Change directory to root\n",
        "Then train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlm1WB93eVYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5561194d-4176-44e5-d5c8-ef26ef5edaa6"
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K61a-WhAX7k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "def main():\n",
        "    # train on the GPU or on the CPU, if a GPU is not available\n",
        "    #Running in GPU will GREATLY INCREASE training time, SO DO IT!!!!\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    #My dataset was utilizing 5 classes, change to your number of classes\n",
        "    num_classes = 5\n",
        "    # use our dataset and defined transformations\n",
        "    dataset = vex('/root/', get_transform(train=True))\n",
        "    dataset_test = vex('/root/', get_transform(train=False))\n",
        "\n",
        "    # define training and validation data loaders\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=4,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "    #get the model using our helper function\n",
        "    model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "    #move model to the right device (cpu or gpu if possible)\n",
        "    model.to(device)\n",
        "\n",
        "    #construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                                momentum=0.9, weight_decay=0.0005)\n",
        "    #and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=3,\n",
        "                                                   gamma=0.1)\n",
        "\n",
        "    #train it for 5 epochs\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "    print(\"training complete!\")\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTFkScsLWbYv",
        "colab_type": "text"
      },
      "source": [
        "Save the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgE5wa4R8X9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model to training/models\n",
        "#remove prior model saves, comment out the following line if you DO NOT want to delete past models\n",
        "!rm -r training\n",
        "!mkdir training\n",
        "torch.save(model.state_dict(), \"/root/training/model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aJm7s_kVDt_",
        "colab_type": "text"
      },
      "source": [
        "Test out your newly saved model on an image from your dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1QrQUzc-IdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "#get saved model\n",
        "loaded_model = get_model_instance_segmentation(num_classes = 5)\n",
        "loaded_model.load_state_dict(torch.load(\"/root/training/model\"))\n",
        "#create new instance of dataset to access images from\n",
        "dataset_test = vex('/root/', get_transform(train=False))\n",
        "#image number\n",
        "idx = 0\n",
        "img, _ = dataset_test[idx]\n",
        "#get the correct labels\n",
        "label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
        "#put the model in evaluation mode\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "   prediction = loaded_model([img])\n",
        "image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
        "draw = ImageDraw.Draw(image)\n",
        "#draws correct labels\n",
        "for elem in range(len(label_boxes)):\n",
        "   draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
        "   (label_boxes[elem][2], label_boxes[elem][3])], \n",
        "   outline =\"green\", width =3)\n",
        "#make predictions\n",
        "for element in range(len(prediction[0][\"boxes\"])):\n",
        "   boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
        "   score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
        "                    decimals= 4)\n",
        "   #change this score to modify the value at which the boxes will be drawn. For example, the default threshold is 0.45, so the model must have atleast \n",
        "   #45% confidence in the location of the box in order to draw it on the image.\n",
        "   if score > 0.45:\n",
        "      draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], \n",
        "      outline =\"red\", width =3)\n",
        "      draw.text((boxes[0], boxes[1]), text = str(score))\n",
        "#display the image\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}